{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matdjohnson-at-umass-dot-edu/cs646-final-project/blob/main/CS646_Final_Project_Classifier_Trainer_Continued_Effort_Instance_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqK9KTy1S5P3",
        "outputId": "456003fb-ed7e-4e65-fda7-b6243ce93d2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.10)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.7)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "! pip install datasets\n",
        "! pip install transformers\n",
        "! pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lc-3AlVxS29g",
        "outputId": "311e9675-00f2-4d51-b493-8a70daee0711"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from datasets import concatenate_datasets, Dataset, disable_caching, disable_progress_bars, load_dataset\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as torch_func\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import gc\n",
        "import time\n",
        "from threading import Lock\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import logging\n",
        "import psutil\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "import random\n",
        "import math\n",
        "import time\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uP6729swv6Qu"
      },
      "outputs": [],
      "source": [
        "\n",
        "class DatasetHolder:\n",
        "    def __init__(self, batch_size=100):\n",
        "        self.batch_size = batch_size\n",
        "        datasets_base_dir = \"/content/drive/MyDrive/CS646-FinalProject/datasets\"\n",
        "        final_dataset_train_file_path_and_name = f\"{datasets_base_dir}/ms_marco_final_dataset_avg/ms_marco_final_dataset_avg_train.parquet\"\n",
        "        final_dataset_train = Dataset.from_parquet(final_dataset_train_file_path_and_name).to_dict(batch_size=10000)\n",
        "        self.query_ids = list()\n",
        "        self.doc_ids = list()\n",
        "        self.query_embs = list()\n",
        "        self.doc_embs = list()\n",
        "        self.labels = list()\n",
        "        for i in tqdm(range(0, len(final_dataset_train['query_id']))):\n",
        "            self.query_ids.append(final_dataset_train['query_id'][i])\n",
        "            self.query_ids.append(final_dataset_train['query_id'][i])\n",
        "            self.doc_ids.append(final_dataset_train['pos_doc_id'][i])\n",
        "            self.doc_ids.append(final_dataset_train['neg_doc_id'][i])\n",
        "            self.query_embs.append(final_dataset_train['query_emb'][i])\n",
        "            self.query_embs.append(final_dataset_train['query_emb'][i])\n",
        "            self.doc_embs.append(final_dataset_train['pos_doc_emb'][i])\n",
        "            self.doc_embs.append(final_dataset_train['neg_doc_emb'][i])\n",
        "            # positive example to provide indicator on logit index 0\n",
        "            self.labels.append(0)\n",
        "            # negative example to provide indicator on logit index 1\n",
        "            self.labels.append(1)\n",
        "        del final_dataset_train\n",
        "        gc.collect()\n",
        "        assert len(self.query_ids) == len(self.doc_ids) == len(self.query_embs) == len(self.doc_embs) == len(self.labels)\n",
        "        self.total_elements = len(self.query_ids)\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    def shuffle(self):\n",
        "        assert len(self.query_ids) == len(self.doc_ids) == len(self.query_embs) == len(self.doc_embs) == len(self.labels)\n",
        "        zipped_list = list(zip(self.query_ids, self.doc_ids, self.query_embs, self.doc_embs, self.labels))\n",
        "        random.shuffle(zipped_list)\n",
        "        self.query_ids, self.doc_ids, self.query_embs, self.doc_embs, self.labels = zip(*zipped_list)\n",
        "\n",
        "    def get_batch_count(self):\n",
        "        batches = (self.total_elements // self.batch_size)\n",
        "        if self.total_elements % self.batch_size != 0:\n",
        "            batches = batches + 1\n",
        "        return batches\n",
        "\n",
        "    def get_query_ids_for_batch_idx(self, batch_idx):\n",
        "        return self.query_ids[self.batch_size*batch_idx:self.batch_size*(batch_idx+1)]\n",
        "\n",
        "    def get_doc_ids_for_batch_idx(self, batch_idx):\n",
        "        return self.doc_ids[self.batch_size*batch_idx:self.batch_size*(batch_idx+1)]\n",
        "\n",
        "    def get_query_embs_for_batch_idx(self, batch_idx):\n",
        "        return torch.tensor(self.query_embs[self.batch_size*batch_idx:self.batch_size*(batch_idx+1)], device=self.device)\n",
        "\n",
        "    def get_doc_embs_for_batch_idx(self, batch_idx):\n",
        "        return torch.tensor(self.doc_embs[self.batch_size*batch_idx:self.batch_size*(batch_idx+1)], device=self.device)\n",
        "\n",
        "    def get_labels_for_batch_idx(self, batch_idx):\n",
        "        return torch.tensor(self.labels[self.batch_size*batch_idx:self.batch_size*(batch_idx+1)], device=self.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XdqGw0b-ma8U"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SimpleAttentionModel_1AttnModule(torch.nn.Module):\n",
        "    def __init__(self, emb_dim=1024, inner_dim=2048, num_attn_heads=1, linear_layer_dim=8196):\n",
        "        super().__init__()\n",
        "        self.query_proj = torch.nn.Linear(in_features=emb_dim*2, out_features=inner_dim)\n",
        "        self.key_proj = torch.nn.Linear(in_features=emb_dim*2, out_features=inner_dim)\n",
        "        self.value_proj = torch.nn.Linear(in_features=emb_dim*2, out_features=inner_dim)\n",
        "        self.layer_1 = torch.nn.MultiheadAttention(embed_dim=inner_dim, num_heads=num_attn_heads, batch_first=True)\n",
        "        self.layer_2 = torch.nn.ReLU()\n",
        "        self.layer_3 = torch.nn.Linear(in_features=inner_dim, out_features=linear_layer_dim)\n",
        "        self.layer_4 = torch.nn.Linear(in_features=linear_layer_dim, out_features=2)\n",
        "        self.layer_5 = torch.nn.LogSoftmax(dim=1)\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(device=device)\n",
        "\n",
        "    def forward(self, query_embs, doc_embs):\n",
        "        assert len(query_embs.shape) == 2 and len(doc_embs.shape) == 2 and query_embs.shape[0] == doc_embs.shape[0] and query_embs.shape[1] == doc_embs.shape[1]\n",
        "        concatenated_embs = torch.concatenate(tensors=[query_embs, doc_embs], axis=-1)\n",
        "        query = self.query_proj(concatenated_embs).unsqueeze(-2)\n",
        "        key = self.key_proj(concatenated_embs).unsqueeze(-2)\n",
        "        value = self.value_proj(concatenated_embs).unsqueeze(-2)\n",
        "        layer_1_output = self.layer_1(\n",
        "            query,\n",
        "            key,\n",
        "            value\n",
        "        )\n",
        "        layer_1_output_squeezed = layer_1_output[0].squeeze(-2)\n",
        "        layer_2_output = self.layer_2(layer_1_output_squeezed)\n",
        "        layer_3_output = self.layer_3(layer_2_output)\n",
        "        layer_4_output = self.layer_4(layer_3_output)\n",
        "        layer_5_output = self.layer_5(layer_4_output)\n",
        "        return layer_5_output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5e3e17e79cb44ed3a9f856fe177af6ea",
            "8942540e9046499fbae2a77797261122",
            "cefdbf49040143beae8c33cdbe25178e",
            "2e303d68bb97435d9dccc3d5a5a59dda",
            "8c0c2a5fb4e8450389d291c44d7cb22f",
            "601e83bcb5c0455d90cc44a3e79eb3b5",
            "ae6532ceb8e3416b9c2fc855bb736587",
            "1f10b9436a3d4e999fe80c73f2c34862",
            "b44d62d4f1084a20b5380666a630f63e",
            "d7c1264c0fee4375b6067329b2ba123a",
            "976ccb382b9948a4887a9283f1916fce"
          ]
        },
        "id": "YIBAaWvvtSce",
        "outputId": "c3d9b7d9-001c-4a75-c968-e394ab00ef19"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5e3e17e79cb44ed3a9f856fe177af6ea",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "hyper_parameters_2024_12_14_03 = {\n",
        "    \"epochs\": 10,\n",
        "    \"max_lr\": 0.00025,\n",
        "    \"fraction_of_epochs_as_warmup\": 0.1,\n",
        "    \"fraction_of_max_lr_at_init\": 0.8,\n",
        "    \"fraction_of_max_lr_at_end\": 0.33,\n",
        "    \"batch_size\": 700,\n",
        "    \"num_attn_modules\": 1,\n",
        "    \"num_attn_heads\": 4,\n",
        "    \"linear_layer_dim\": 8196,\n",
        "    \"parameter_set_name\": \"hyper_parameters_2024_12_14_03\"\n",
        "}\n",
        "\n",
        "hyper_parameters = hyper_parameters_2024_12_14_03\n",
        "\n",
        "# dataset_holder = DatasetHolder(batch_size=hyper_parameters['batch_size'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5rsI6shjCHu"
      },
      "outputs": [],
      "source": [
        "model = SimpleAttentionModel_1AttnModule(\n",
        "    num_attn_heads=hyper_parameters['num_attn_heads'],\n",
        "    linear_layer_dim=hyper_parameters['linear_layer_dim']\n",
        ")\n",
        "\n",
        "iters_warmup = math.floor(hyper_parameters[\"epochs\"] * hyper_parameters[\"fraction_of_epochs_as_warmup\"])\n",
        "iters_cooldown = hyper_parameters['epochs'] - iters_warmup\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyper_parameters['max_lr'])\n",
        "warmup_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=(hyper_parameters['fraction_of_max_lr_at_init']), end_factor=(1.0), total_iters=iters_warmup)\n",
        "cooldown_scheduler = torch.optim.lr_scheduler.LinearLR(optimizer, start_factor=(1.0), end_factor=(hyper_parameters['fraction_of_max_lr_at_end']), total_iters=iters_cooldown)\n",
        "scheduler = torch.optim.lr_scheduler.SequentialLR(optimizer, schedulers=[warmup_scheduler, cooldown_scheduler], milestones=[iters_warmup])\n",
        "loss_fcn = torch.nn.NLLLoss(reduction='mean')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyNGSb77NwQv"
      },
      "outputs": [],
      "source": [
        "# timestamp = time.strftime(\"%Y%m%dT%H%M%S\", time.localtime())\n",
        "timestamp = \"20241215T170255\"\n",
        "\n",
        "logs_dir = f\"/content/drive/MyDrive/CS646-FinalProject/training_runs\"\n",
        "log_dir = f\"{logs_dir}/{hyper_parameters['parameter_set_name']}-{timestamp}\"\n",
        "models_dir = \"/content/drive/MyDrive/CS646-FinalProject/models\"\n",
        "model_parameter_file = f\"{models_dir}/{hyper_parameters['parameter_set_name']}-{timestamp}.pt\"\n",
        "\n",
        "! mkdir -p {log_dir}\n",
        "\n",
        "print(f\"created log directory {log_dir}\")\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjDV9hShUQcA"
      },
      "outputs": [],
      "source": [
        "tensorboard_writer = SummaryWriter(log_dir=log_dir)\n",
        "\n",
        "for i in range(0, hyper_parameters[\"epochs\"]):\n",
        "    dataset_holder.shuffle()\n",
        "    for j in range(0, dataset_holder.get_batch_count()):\n",
        "        query_embs = dataset_holder.get_query_embs_for_batch_idx(j)\n",
        "        doc_embs = dataset_holder.get_doc_embs_for_batch_idx(j)\n",
        "        labels = dataset_holder.get_labels_for_batch_idx(j)\n",
        "        model.zero_grad()\n",
        "        logits = model.forward(query_embs, doc_embs)\n",
        "        loss = loss_fcn(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        timestamp = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.localtime())\n",
        "        print(f\"{timestamp} epoch:{i}/{hyper_parameters['epochs']} batch:{j}/{dataset_holder.get_batch_count()} lr:{scheduler.get_last_lr()} loss:{loss} memory:{torch.cuda.mem_get_info()}\")\n",
        "        iteration = i * dataset_holder.get_batch_count() + j\n",
        "        tensorboard_writer.add_scalar(\"lr\", scheduler.get_last_lr()[0], global_step=iteration)\n",
        "        tensorboard_writer.add_scalar(\"loss\", loss, global_step=iteration)\n",
        "        tensorboard_writer.add_scalar(\"memory\", torch.cuda.mem_get_info()[1] - torch.cuda.mem_get_info()[0], global_step=iteration)\n",
        "        tensorboard_writer.flush()\n",
        "        # if j == dataset_holder.get_batch_count() - 1:\n",
        "        #     print(f\"{timestamp} logits_and_labels:{torch.concatenate([logits, labels.unsqueeze(-1)], dim=1)}\")\n",
        "        del query_embs, doc_embs, labels, logits, loss\n",
        "        gc.collect()\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "    scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wS7POfyUSUI"
      },
      "outputs": [],
      "source": [
        "model.zero_grad()\n",
        "model.eval()\n",
        "torch.save(model, model_parameter_file)\n",
        "\n",
        "print(f\"wrote parameters to {model_parameter_file}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyMO/2bKH5FZGlmdHLbeZ0Fv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1f10b9436a3d4e999fe80c73f2c34862": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2e303d68bb97435d9dccc3d5a5a59dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c1264c0fee4375b6067329b2ba123a",
            "placeholder": "​",
            "style": "IPY_MODEL_976ccb382b9948a4887a9283f1916fce",
            "value": " 201396/0 [00:33&lt;00:00, 5576.93 examples/s]"
          }
        },
        "5e3e17e79cb44ed3a9f856fe177af6ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8942540e9046499fbae2a77797261122",
              "IPY_MODEL_cefdbf49040143beae8c33cdbe25178e",
              "IPY_MODEL_2e303d68bb97435d9dccc3d5a5a59dda"
            ],
            "layout": "IPY_MODEL_8c0c2a5fb4e8450389d291c44d7cb22f"
          }
        },
        "601e83bcb5c0455d90cc44a3e79eb3b5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8942540e9046499fbae2a77797261122": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_601e83bcb5c0455d90cc44a3e79eb3b5",
            "placeholder": "​",
            "style": "IPY_MODEL_ae6532ceb8e3416b9c2fc855bb736587",
            "value": "Generating train split: "
          }
        },
        "8c0c2a5fb4e8450389d291c44d7cb22f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "976ccb382b9948a4887a9283f1916fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae6532ceb8e3416b9c2fc855bb736587": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b44d62d4f1084a20b5380666a630f63e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cefdbf49040143beae8c33cdbe25178e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f10b9436a3d4e999fe80c73f2c34862",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b44d62d4f1084a20b5380666a630f63e",
            "value": 1
          }
        },
        "d7c1264c0fee4375b6067329b2ba123a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}