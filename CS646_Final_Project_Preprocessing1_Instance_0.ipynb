{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matdjohnson-at-umass-dot-edu/cs646-final-project/blob/main/CS646_Final_Project_Preprocessing1_Instance_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDHOQ5UWN6i_"
      },
      "outputs": [],
      "source": [
        "! pip install datasets\n",
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_eYAgbYyFn_"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, concatenate_datasets\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from datasets import load_from_disk\n",
        "from datasets import Dataset\n",
        "import os\n",
        "import torch\n",
        "import gc\n",
        "import time\n",
        "from threading import Lock\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import logging\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srmbQZImrzhh"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_in_qrel') \\\n",
        "    or not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_not_in_qrel') \\\n",
        "    or not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_in_qrel') \\\n",
        "    or not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_not_in_qrel'):\n",
        "\n",
        "    qrels = load_dataset('BeIR/msmarco-qrels')\n",
        "\n",
        "    print(qrels)\n",
        "\n",
        "    train_corpus_ids = list()\n",
        "    train_queries_ids = list()\n",
        "    for entry in qrels['train']:\n",
        "        train_corpus_ids.append(entry['corpus-id'])\n",
        "        train_queries_ids.append(entry['query-id'])\n",
        "    train_queries_ids = list(set(train_queries_ids))\n",
        "    train_corpus_ids = list(set(train_corpus_ids))\n",
        "\n",
        "    validation_corpus_ids = list()\n",
        "    validation_queries_ids = list()\n",
        "    for entry in qrels['validation']:\n",
        "        validation_corpus_ids.append(entry['corpus-id'])\n",
        "        validation_queries_ids.append(entry['query-id'])\n",
        "    validation_corpus_ids = list(set(validation_corpus_ids))\n",
        "    validation_queries_ids = list(set(validation_queries_ids))\n",
        "\n",
        "    test_corpus_ids = list()\n",
        "    test_queries_ids = list()\n",
        "    for entry in qrels['test']:\n",
        "        test_corpus_ids.append(entry['corpus-id'])\n",
        "        test_queries_ids.append(entry['query-id'])\n",
        "    test_queries_ids = list(set(test_queries_ids))\n",
        "    test_corpus_ids = list(set(test_corpus_ids))\n",
        "\n",
        "    corpus_ids = set(train_corpus_ids + validation_corpus_ids + test_corpus_ids)\n",
        "    queries_ids = set(train_queries_ids + validation_queries_ids + test_queries_ids)\n",
        "\n",
        "    print(f\"len(corpus_ids):{len(corpus_ids)} len(train_corpus_ids):{len(train_corpus_ids)} len(validation_corpus_ids):{len(validation_corpus_ids)} len(test_corpus_ids):{len(test_corpus_ids)}\")\n",
        "    print(f\"len(queries_ids):{len(queries_ids)} len(train_queries_ids):{len(train_queries_ids)} len(validation_queries_ids):{len(validation_queries_ids)} len(test_queries_ids):{len(test_queries_ids)}\")\n",
        "\n",
        "    ms_marco_corpus = load_dataset('BeIR/msmarco', 'corpus')\n",
        "    ms_marco_queries = load_dataset('BeIR/msmarco', 'queries')\n",
        "\n",
        "    print(ms_marco_corpus)\n",
        "\n",
        "    ms_marco_corpus_in_qrel = ms_marco_corpus['corpus'].filter(lambda example: int(example['_id']) in corpus_ids)\n",
        "    ms_marco_corpus_not_in_qrel = ms_marco_corpus['corpus'].filter(lambda example: int(example['_id']) not in corpus_ids)\n",
        "\n",
        "    ms_marco_queries_in_qrel = ms_marco_queries['queries'].filter(lambda example: int(example['_id']) in queries_ids)\n",
        "    ms_marco_queries_not_in_qrel = ms_marco_queries['queries'].filter(lambda example: int(example['_id']) not in queries_ids)\n",
        "\n",
        "    print(ms_marco_corpus_in_qrel)\n",
        "    print(ms_marco_corpus_not_in_qrel)\n",
        "    print(ms_marco_queries_in_qrel)\n",
        "    print(ms_marco_queries_not_in_qrel)\n",
        "\n",
        "    if not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_in_qrel'):\n",
        "        os.makedirs('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_in_qrel')\n",
        "    ms_marco_corpus_in_qrel.save_to_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_in_qrel', max_shard_size='250MB')\n",
        "    if not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_not_in_qrel'):\n",
        "        os.makedirs('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_not_in_qrel')\n",
        "    ms_marco_corpus_not_in_qrel.save_to_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_not_in_qrel', max_shard_size='250MB')\n",
        "    if not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_in_qrel'):\n",
        "        os.makedirs('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_in_qrel')\n",
        "    ms_marco_queries_in_qrel.save_to_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_in_qrel', max_shard_size='250MB')\n",
        "    if not os.path.exists('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_not_in_qrel'):\n",
        "        os.makedirs('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_not_in_qrel')\n",
        "    ms_marco_queries_not_in_qrel.save_to_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_not_in_qrel', max_shard_size='250MB')\n",
        "\n",
        "else:\n",
        "    ms_marco_corpus_in_qrel = load_from_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_in_qrel')\n",
        "    ms_marco_corpus_in_qrel = ms_marco_corpus_in_qrel.remove_columns(['tokenization', 'embedding'])\n",
        "    ms_marco_corpus_not_in_qrel = load_from_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_not_in_qrel')\n",
        "    ms_marco_corpus_not_in_qrel = ms_marco_corpus_not_in_qrel.remove_columns(['tokenization', 'embedding'])\n",
        "    ms_marco_queries_in_qrel = load_from_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_in_qrel')\n",
        "    ms_marco_queries_in_qrel = ms_marco_queries_in_qrel.remove_columns(['tokenization', 'embedding'])\n",
        "    ms_marco_queries_not_in_qrel = load_from_disk('/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_not_in_qrel')\n",
        "    ms_marco_queries_not_in_qrel = ms_marco_queries_not_in_qrel.remove_columns(['tokenization', 'embedding'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kLTypbMJaiP0"
      },
      "outputs": [],
      "source": [
        "model_name = 'princeton-nlp/sup-simcse-roberta-large'\n",
        "max_model_pool_size = 25\n",
        "dataset_start_ind = 937500\n",
        "dataset_end_ind = 1000000\n",
        "log_frequency = 10\n",
        "\n",
        "class ModelHolder:\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "def populate_model_pool(model_pool=list(), pool_size=7):\n",
        "    for i in range(0, pool_size):\n",
        "        model_pool.append(\n",
        "            ModelHolder(\n",
        "                AutoModel.from_pretrained(model_name).cuda(),\n",
        "                AutoTokenizer.from_pretrained(model_name)\n",
        "            )\n",
        "        )\n",
        "    return model_pool\n",
        "\n",
        "def process_batch(batch_num, log_dir, tokenizer, model, batch):\n",
        "    tokenizations = list()\n",
        "    embeddings = list()\n",
        "    for i in range(0, len(batch)):\n",
        "        tokenization = tokenizer(batch['text'][i], padding=True, truncation=True, return_tensors='pt').to('cuda')\n",
        "        model_output = model(**tokenization, return_dict=True)\n",
        "        embeddings.append(model_output.last_hidden_state.detach().to('cpu').numpy().flatten())\n",
        "        tokenizations.append(tokenization['input_ids'].detach().to('cpu').numpy().flatten())\n",
        "        del model_output\n",
        "        del tokenization\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        if (i+1) % log_frequency == 0 or (i+1) == 1:\n",
        "            timestamp = time.strftime(\"%Y-%m-%dT%H:%M:%S\", time.localtime())\n",
        "            log_file = open(f\"{log_dir}/batch-{dataset_start_ind}-{dataset_end_ind}.log\", \"a\")\n",
        "            log_file.write(f\"{timestamp}: batch-runner-{batch_num} - completed {i+1} of {len(batch)}\\n\")\n",
        "            log_file.close()\n",
        "    return batch, tokenizations, embeddings\n",
        "\n",
        "model_pool = populate_model_pool(pool_size=max_model_pool_size)\n",
        "executor = ThreadPoolExecutor(max_workers=max_model_pool_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zY0n_sXrlHGi"
      },
      "outputs": [],
      "source": [
        "# corpus_dir_for_batch = f\"/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_in_qrel_embs_{dataset_start_ind}-{dataset_end_ind}\"\n",
        "corpus_dir_for_batch = f\"/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_corpus_not_in_qrel_embs_{dataset_start_ind}-{dataset_end_ind}\"\n",
        "# corpus_dir_for_batch = f\"/content/drive/MyDrive/CS646-FinalProject/datasets/ms_marco_queries_in_qrel_embs_{dataset_start_ind}-{dataset_end_ind}\"\n",
        "\n",
        "if not os.path.exists(corpus_dir_for_batch):\n",
        "    os.makedirs(corpus_dir_for_batch)\n",
        "\n",
        "futures_list = list()\n",
        "\n",
        "# ms_marco_corpus_selection = ms_marco_corpus_in_qrel.select(range(dataset_start_ind, dataset_end_ind))\n",
        "ms_marco_corpus_selection = ms_marco_corpus_not_in_qrel.select(range(dataset_start_ind, dataset_end_ind))\n",
        "# ms_marco_corpus_selection = ms_marco_queries_in_qrel.select(range(dataset_start_ind, dataset_end_ind))\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "for i in range(0, max_model_pool_size):\n",
        "    batch_size = (dataset_end_ind - dataset_start_ind) // max_model_pool_size\n",
        "    batch_lower_bound = i * batch_size\n",
        "    if i == max_model_pool_size - 1:\n",
        "        batch_upper_bound = batch_upper_bound = len(ms_marco_corpus_selection)\n",
        "    else:\n",
        "        batch_upper_bound = (i+1) * batch_size\n",
        "    batch = ms_marco_corpus_selection.select(range(batch_lower_bound, batch_upper_bound))\n",
        "    future = executor.submit(process_batch, i, corpus_dir_for_batch, model_pool[i].tokenizer, model_pool[i].model, batch)\n",
        "    futures_list.append(future)\n",
        "\n",
        "ms_marco_corpus_selection_preprocessed_list = list()\n",
        "while len(futures_list) > 0:\n",
        "    for i in range(0, len(futures_list)):\n",
        "        future = futures_list[i]\n",
        "        if future.done():\n",
        "            batch, tokenizations, embeddings = future.result()\n",
        "            batch = batch.add_column('tokenization', tokenizations)\n",
        "            batch = batch.add_column('embedding', embeddings)\n",
        "            ms_marco_corpus_selection_preprocessed_list.append(batch)\n",
        "            futures_list.pop(i)\n",
        "            break\n",
        "\n",
        "for i in range(0, len(ms_marco_corpus_selection_preprocessed_list)):\n",
        "    ms_marco_corpus_selection_preprocessed_list[i].to_parquet(corpus_dir_for_batch + f\"/subset_{i}.parquet\")\n",
        "\n",
        "ms_marco_corpus_selection_preprocessed = concatenate_datasets(ms_marco_corpus_selection_preprocessed_list)\n",
        "print(ms_marco_corpus_selection_preprocessed)\n",
        "for i in range(10):\n",
        "    print(f\"{ms_marco_corpus_selection_preprocessed[i]}\"[:1500])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}